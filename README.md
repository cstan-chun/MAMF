#  MAMF: Mutual Attention-Based Multimodal Fusion for Audio-Visual Emotion Recognition
## Environment setup
1. create a new environment using conda or pip (python==3.8)
2. pip install -r requirements.txt
## Download Data
The two datasets (RAVDESS,IEMOCAP) are available from this link:
1. [https://zenodo.org/records/1188976#.ZECaH3ZBw2x](https://zenodo.org/records/1188976#.ZECaH3ZBw2x) This data is divided into song and speech, and you only need to download the speech.
2. [https://gitcode.com/Open-source-documentation-tutorial/0e833/tree/main](https://gitcode.com/Open-source-documentation-tutorial/0e833/tree/main)
## data processing
### RAVDESS

## train
RAVDESS
└───ACTOR01
│   │  01-01-01-01-01-01-01.mp4
│   │  01-01-01-01-01-02-01.mp4
│   │  ...
│   │  03-01-01-01-01-01-01.wav
│   │  03-01-01-01-01-02-01.wav
│   │  ...
└───ACTOR02
└───...
└───ACTOR24
